Here is the prompt in English:

1. Large Language Model Inference Acceleration

Relevant: Novel inference acceleration frameworks such as dynamic batching, adaptive computation, model compression and quantization. Focus on acceleration algorithms and architectural innovations that significantly improve throughput.


2. Complex Reasoning Enhancement for LLMs

Relevant: Novel methods for enhancing model capabilities in multi-step reasoning, logical analysis, and complex problem decomposition. Emphasis on reasoning frameworks with interpretability guarantees and innovative algorithms that effectively improve reasoning accuracy.
Not relevant: Methods relying solely on prompting engineering or techniques that do not fundamentally improve model reasoning capabilities.


3. Test-time Scaling for LLMs

Relevant: the test-time scaling algorithms of LLMs, scuh as beam search, tree search



When recommending papers, special attention should be paid to:
1. Research proposing novel statistical or computational frameworks
2. Key findings about LLM inference efficiency and quality
3. Innovative mathematical methods for solving acceleration and scalability challenges