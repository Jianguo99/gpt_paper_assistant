[SELECTION]
# whether to use the local LLM
local_llm = true 
local_model = meta-llama/Llama-3.1-8B-Instruct
remote_model = claude-3-5-sonnet-20241022
author_match_score = 15.0
# DO NOT USE GPT 3.5 TURBO EXCEPT FOR DEBUGGING
#model = gpt-3.5-turbo
#model = gpt-3.5-turbo-1106
#model = gpt-4

# cost quality tradeoff - larger batches are cheaper but less accurate.
batch_size = 5

[FILTERING]
arxiv_category = cs.CL,cs.LG,cs.AI,stat.ML,cs.CV,math.ST
; arxiv_category = cs.CL
# force_primary ignores papers that are only cross-listed into the arxiv_category
force_primary = true
# draws num_samples samples from the LM and averages scores
num_samples = 1
# the min hindex of the authors
hcutoff = 15
relevance_cutoff = 3
novelty_cutoff = 3
# whether to do author matching
author_match = false
topic = configs/paper_conformal.txt

[OUTPUT]
debug_messages = true
dump_debug_file = true
output_path = out/
# options: json, md, slack
dump_json = true
dump_md = true
push_to_slack = true
filename = conformal